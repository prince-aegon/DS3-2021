{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakJha-IITMandi/DS3-2021/blob/main/LSTM_IITMandi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i7ArNBLRY7v"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUdAFS6fRSjx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses as lo_ss\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import string\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report , roc_auc_score\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from google.colab import drive\n",
        "from numpy import savetxt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MZBJyCBRfKK"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report , roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlRcU2yORl7t"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F7fpFDRcX2j"
      },
      "source": [
        "### Reading data and standardizing it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHkPoje_RhBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c938ca45-84de-403f-87a3-2f69fee9ccc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4035, 155)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Reading data from csv file\n",
        "\n",
        "import os\n",
        "github_raw_link=\"https://raw.githubusercontent.com/Aryansh085/LAP/main/858417d1-7d54-4115-a01b-fdda5e03ada3_testing_combined_rows4035_disc_1_0p9_MULTIPLY_preproces_155cols.csv\"\n",
        "df1=pd.read_csv((github_raw_link),header = None)\n",
        "df1=np.array(df1)\n",
        "\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "64nmpIjURpDO",
        "outputId": "68689581-c5ac-4257-d425-4f8f4a507678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  1.750036  0.350342 -1.341973 -2.795068  0.432952  0.474938 -1.574554   \n",
              "1 -0.254578  1.008169  0.819884 -1.666252 -0.495354 -0.246320 -0.306173   \n",
              "2 -0.546815 -0.789877 -0.896693  0.609252 -1.785813  0.671458 -1.346309   \n",
              "3  1.129433  1.576726 -1.089738 -0.159556 -0.237411 -0.771867  1.524618   \n",
              "4 -0.692797 -0.435498 -1.673149  0.045856  0.292185 -1.561811  0.780544   \n",
              "\n",
              "        7         8         9    ...       140       141       142       143  \\\n",
              "0 -0.439485 -1.486932 -1.585869  ... -1.015021 -0.795066 -1.952407 -0.866407   \n",
              "1 -0.182138  0.162858 -0.850303  ...  1.485140 -0.294316  1.076433 -0.578114   \n",
              "2  0.051911  1.257504  0.635510  ...  1.064428  0.506085 -0.692270  0.803917   \n",
              "3 -0.068071 -0.171521  0.341681  ... -0.958503 -0.795708 -0.132790  0.018378   \n",
              "4 -0.000231 -1.402506  0.866888  ...  0.353773 -1.160216 -0.357106  0.220035   \n",
              "\n",
              "        144       145       146       147       148       149  \n",
              "0 -3.145759  3.099274 -0.818265 -0.095863 -0.652975 -0.693894  \n",
              "1  0.625668  0.116021  1.182070  0.071192  1.467883  0.099011  \n",
              "2  0.736296 -0.473514  0.512632 -0.367337 -0.455865 -0.193491  \n",
              "3 -0.432966 -0.066116 -0.006371 -0.472373  0.181778  0.074862  \n",
              "4  0.144812 -0.401812  0.585473 -0.644445  0.811905 -0.621054  \n",
              "\n",
              "[5 rows x 150 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d738fb77-9d06-4f12-82b8-fda4995721a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.750036</td>\n",
              "      <td>0.350342</td>\n",
              "      <td>-1.341973</td>\n",
              "      <td>-2.795068</td>\n",
              "      <td>0.432952</td>\n",
              "      <td>0.474938</td>\n",
              "      <td>-1.574554</td>\n",
              "      <td>-0.439485</td>\n",
              "      <td>-1.486932</td>\n",
              "      <td>-1.585869</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.015021</td>\n",
              "      <td>-0.795066</td>\n",
              "      <td>-1.952407</td>\n",
              "      <td>-0.866407</td>\n",
              "      <td>-3.145759</td>\n",
              "      <td>3.099274</td>\n",
              "      <td>-0.818265</td>\n",
              "      <td>-0.095863</td>\n",
              "      <td>-0.652975</td>\n",
              "      <td>-0.693894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.254578</td>\n",
              "      <td>1.008169</td>\n",
              "      <td>0.819884</td>\n",
              "      <td>-1.666252</td>\n",
              "      <td>-0.495354</td>\n",
              "      <td>-0.246320</td>\n",
              "      <td>-0.306173</td>\n",
              "      <td>-0.182138</td>\n",
              "      <td>0.162858</td>\n",
              "      <td>-0.850303</td>\n",
              "      <td>...</td>\n",
              "      <td>1.485140</td>\n",
              "      <td>-0.294316</td>\n",
              "      <td>1.076433</td>\n",
              "      <td>-0.578114</td>\n",
              "      <td>0.625668</td>\n",
              "      <td>0.116021</td>\n",
              "      <td>1.182070</td>\n",
              "      <td>0.071192</td>\n",
              "      <td>1.467883</td>\n",
              "      <td>0.099011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.546815</td>\n",
              "      <td>-0.789877</td>\n",
              "      <td>-0.896693</td>\n",
              "      <td>0.609252</td>\n",
              "      <td>-1.785813</td>\n",
              "      <td>0.671458</td>\n",
              "      <td>-1.346309</td>\n",
              "      <td>0.051911</td>\n",
              "      <td>1.257504</td>\n",
              "      <td>0.635510</td>\n",
              "      <td>...</td>\n",
              "      <td>1.064428</td>\n",
              "      <td>0.506085</td>\n",
              "      <td>-0.692270</td>\n",
              "      <td>0.803917</td>\n",
              "      <td>0.736296</td>\n",
              "      <td>-0.473514</td>\n",
              "      <td>0.512632</td>\n",
              "      <td>-0.367337</td>\n",
              "      <td>-0.455865</td>\n",
              "      <td>-0.193491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.129433</td>\n",
              "      <td>1.576726</td>\n",
              "      <td>-1.089738</td>\n",
              "      <td>-0.159556</td>\n",
              "      <td>-0.237411</td>\n",
              "      <td>-0.771867</td>\n",
              "      <td>1.524618</td>\n",
              "      <td>-0.068071</td>\n",
              "      <td>-0.171521</td>\n",
              "      <td>0.341681</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.958503</td>\n",
              "      <td>-0.795708</td>\n",
              "      <td>-0.132790</td>\n",
              "      <td>0.018378</td>\n",
              "      <td>-0.432966</td>\n",
              "      <td>-0.066116</td>\n",
              "      <td>-0.006371</td>\n",
              "      <td>-0.472373</td>\n",
              "      <td>0.181778</td>\n",
              "      <td>0.074862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.692797</td>\n",
              "      <td>-0.435498</td>\n",
              "      <td>-1.673149</td>\n",
              "      <td>0.045856</td>\n",
              "      <td>0.292185</td>\n",
              "      <td>-1.561811</td>\n",
              "      <td>0.780544</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-1.402506</td>\n",
              "      <td>0.866888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.353773</td>\n",
              "      <td>-1.160216</td>\n",
              "      <td>-0.357106</td>\n",
              "      <td>0.220035</td>\n",
              "      <td>0.144812</td>\n",
              "      <td>-0.401812</td>\n",
              "      <td>0.585473</td>\n",
              "      <td>-0.644445</td>\n",
              "      <td>0.811905</td>\n",
              "      <td>-0.621054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 150 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d738fb77-9d06-4f12-82b8-fda4995721a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d738fb77-9d06-4f12-82b8-fda4995721a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d738fb77-9d06-4f12-82b8-fda4995721a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Making a new dataframe which contains only relevant features\n",
        "df = df1[:,5:]\n",
        "df = np.array(df)\n",
        "\n",
        "# Standardizing data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "slr=StandardScaler()\n",
        "slr.fit(df)\n",
        "df = slr.transform(df)\n",
        "\n",
        "# final dataframe\n",
        "df=pd.DataFrame(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAspHsJlcg7D"
      },
      "source": [
        "### Manipulating data according to the timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzzVmtjWSlUp"
      },
      "outputs": [],
      "source": [
        "# timestamp is defined here \n",
        "t = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D2GAI2UTMmx",
        "outputId": "de3c8a9a-5c75-4385-be11-6aaf1ad5f28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 2., 2., ..., 0., 2., 2.]), (4030,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Storing output corresponding to the new dataframe and according to the timestamp\n",
        "y=np.array(df1[:,0])\n",
        "y=y[t:]\n",
        "\n",
        "y, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1zhEPi3TEfr",
        "outputId": "1a80e5a0-eff2-4d1f-a86f-ecfa073fa516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4030, 5, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Making 3d array where each row contains last t rows information of the data\n",
        "x = np.array(df)\n",
        "# print(x.shape,y.shape)\n",
        "\n",
        "x_3d = []\n",
        "for i in range(4035-t):\n",
        "  tmp = []\n",
        "  for j in range(t):\n",
        "    tmp.append(x[j+i])\n",
        "  x_3d.append(tmp)\n",
        "x_3d = np.array(x_3d)\n",
        "x_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVNlv0c_T4qS"
      },
      "outputs": [],
      "source": [
        "# making test and train input and output data for the lstm layer\n",
        "total_size = x_3d.shape[0]\n",
        "\n",
        "# assigning train-test ratio to split data in train-test\n",
        "train_test_ratio=0.8\n",
        "train_size = int(total_size * train_test_ratio)\n",
        "test_size = total_size - train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMscl0J2ndvR",
        "outputId": "ea566ec9-9841-4989-c6a7-b806611b49eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3262, 5, 150) (3262,)\n",
            "(768, 5, 150) (768,)\n"
          ]
        }
      ],
      "source": [
        "# these array will contain test and train data\n",
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "\n",
        "# Random assignment of data : filling the test and train data randomly\n",
        "for i in range(x_3d.shape[0]):\n",
        "  feature = []\n",
        "  corr_output = []\n",
        "\n",
        "  no = np.random.randint(100)\n",
        "\n",
        "  if(no < 80):\n",
        "    feature = x_3d[i]\n",
        "    corr_output = y[i]\n",
        "\n",
        "    x_train.append(feature) \n",
        "    y_train.append(corr_output) \n",
        "\n",
        "  else:\n",
        "    feature = x_3d[i]\n",
        "    corr_output = y[i]\n",
        "\n",
        "    x_test.append(feature) \n",
        "    y_test.append(corr_output) \n",
        "\n",
        "# changing each to np array\n",
        "main_x_train = np.array(x_train)\n",
        "main_y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(main_x_train.shape, main_y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDH4gayJnpdh"
      },
      "outputs": [],
      "source": [
        "# Sequentially assignment of data : Taking the first data as train data and last one as test data\n",
        "x_train = x_3d[ : train_size]; x_test = x_3d[train_size : ]\n",
        "y_train = y[ : train_size]; y_test = y[train_size : ]\n",
        "\n",
        "# changing each to np array\n",
        "main_x_train = np.array(x_train)\n",
        "main_y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(main_x_train.shape, main_y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwZZ043YWsiZ"
      },
      "outputs": [],
      "source": [
        "# count of values in different classes\n",
        "class0_count = np.count_nonzero(main_y_train == 0)\n",
        "class1_count = np.count_nonzero(main_y_train == 1)\n",
        "class2_count = np.count_nonzero(main_y_train == 2)\n",
        "\n",
        "print(class0_count, class1_count, class2_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANRt5wc-bqI3"
      },
      "source": [
        "### Handling Class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3DPIQh9Xpoy",
        "outputId": "2e83ee07-591e-47bb-c0f9-ad6977acc016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4558, 5, 150) (4558,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1483, 1459, 1616)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Random Over-sampling\n",
        "x_train_1, y_train_1 = [], []\n",
        "c1, c2, c3 = 0, 0, 0\n",
        "\n",
        "for i in range(main_x_train.shape[0]):\n",
        "  if(y_train[i] == 0):\n",
        "    x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(0)\n",
        "    c1+=1\n",
        "  elif(y_train[i] == 1):\n",
        "    x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(1)\n",
        "    c2+=1\n",
        "  elif(y_train[i] == 2 ):\n",
        "    x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(2)\n",
        "    c3=c3+1\n",
        "\n",
        "for i in range(main_x_train.shape[0]):\n",
        "  if(y_train[i] == 1):\n",
        "    no = np.random.randint(100)\n",
        "    if(no >= 30):\n",
        "      x_train_1.append(main_x_train[i])\n",
        "      y_train_1.append(1)\n",
        "      c2 += 1\n",
        "  elif(y_train[i] == 2 ):\n",
        "    no = np.random.randint(100)\n",
        "    if(no >= 27):\n",
        "      x_train_1.append(main_x_train[i])\n",
        "      y_train_1.append(2)\n",
        "      c3 += 1\n",
        "\n",
        "x_train = x_train_1; y_train = y_train_1\n",
        "x_train = np.array(x_train); y_train = np.array(y_train)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "c1, c2, c3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2mxJhhbhqTf"
      },
      "outputs": [],
      "source": [
        "# Over-sampling with repeating just after\n",
        "x_train_1, y_train_1 = [], []\n",
        "c1, c2, c3 = 0, 0, 0\n",
        "\n",
        "for i in range(main_x_train.shape[0]):\n",
        "  if(y_train[i] == 0):\n",
        "    x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(0)\n",
        "    c1 += 1\n",
        "  elif(y_train[i] == 1):\n",
        "    x_train_1.append(main_x_train[i]); x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(1); y_train_1.append(1)\n",
        "    c2 += 2\n",
        "  elif(y_train[i] == 2 ):\n",
        "    x_train_1.append(main_x_train[i]); x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(2); y_train_1.append(2)\n",
        "    c3 += 2\n",
        "\n",
        "x_train = x_train_1; y_train = y_train_1\n",
        "x_train = np.array(x_train); y_train = np.array(y_train)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "c1, c2, c3, c1 + c2 + c3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6E7xmIMihDA"
      },
      "outputs": [],
      "source": [
        "# Random under-sampling \n",
        "\n",
        "print(\"main_x_train : \", main_x_train.shape)\n",
        "\n",
        "x_train_1, y_train_1 = [], []\n",
        "c1, c2, c3 = 0, 0, 0\n",
        "\n",
        "for i in range(main_x_train.shape[0]):\n",
        "  if(main_y_train[i] == 0):\n",
        "    to_take = np.random.randint(100)\n",
        "    if(to_take > 50):\n",
        "      x_train_1.append(main_x_train[i])\n",
        "      y_train_1.append(0)\n",
        "      c1 += 1\n",
        "  elif(main_y_train[i] == 1):\n",
        "    x_train_1.append(main_x_train[i]) #; x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(1) #; y_train_1.append(1)\n",
        "    c2 += 1\n",
        "  elif(main_y_train[i] == 2 ):\n",
        "    x_train_1.append(main_x_train[i]) #; x_train_1.append(main_x_train[i])\n",
        "    y_train_1.append(2) #; y_train_1.append(2)\n",
        "    c3 += 1\n",
        "\n",
        "x_train = x_train_1; y_train = y_train_1\n",
        "x_train = np.array(x_train); y_train = np.array(y_train)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "c1, c2, c3, c1 + c2 + c3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASI5AiW6Ykc5",
        "outputId": "0c4d0a12-1228-4896-a8a5-e1641913b2d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0317129629629629, 1: 1.0433052434456929, 2: 0.9326218874241473}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Different weights for the classes to be assigned\n",
        "\n",
        "sklearn_weights = class_weight.compute_class_weight(class_weight = 'balanced',classes = np.unique(y_train),y = y_train)\n",
        "sklearn_weights = dict(zip(np.unique(y_train),sklearn_weights))\n",
        "\n",
        "# manually assigning weights\n",
        "# sklearn_weights={0:1738,1:2348,2:2362}\n",
        "\n",
        "sklearn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhdKhyvAcIy2"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RIlnLxNdPZL"
      },
      "source": [
        "### F1-score function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_-fROlJdTpB"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "\n",
        "#import keras backend\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "# f1-score function\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCn0h4UagIq4"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ug0N9Xzb_GE"
      },
      "outputs": [],
      "source": [
        "# Model 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(t ,150,)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
        "test_output = model.predict(x_test, verbose=1)\n",
        "# history = model.fit(X, Y, epochs=1000, validation_split=0.2, verbose=1)\n",
        "# test_output = model.predict(x=, verbose=0)\n",
        "# print(test_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to return the model so that we can save it"
      ],
      "metadata": {
        "id": "QDOwOCQGZVeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=( t,150,)))\n",
        "  model.add(LSTM(400, activation='relu', return_sequences=True))\n",
        "  model.add(LSTM(800, activation='relu', return_sequences=True))\n",
        "  model.add(LSTM(150, activation='relu'))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(3,activation='sigmoid'))\n",
        "  optimi=keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimi, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "a9YyfFP8ZUQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with class weights\n",
        "model=create_model()\n",
        "# history = model.fit(x_train, y_train, epochs=30, validation_split=0.2, verbose=1)\n",
        "history = model.fit(x_train, y_train, epochs=25, validation_split=0.2, verbose=1,class_weight=sklearn_weights)\n",
        "model.save('model.h5')\n",
        "test_output = model.predict(x_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjJep86-ZjWz",
        "outputId": "4ef5869d-18bf-40a8-cb2a-bf162ee416d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "112/112 [==============================] - 15s 55ms/step - loss: 1.0861 - accuracy: 0.4025 - val_loss: 1.2423 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 5s 48ms/step - loss: 1.0248 - accuracy: 0.4755 - val_loss: 1.0999 - val_accuracy: 0.3733\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.8522 - accuracy: 0.5919 - val_loss: 1.0014 - val_accuracy: 0.4854\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 5s 49ms/step - loss: 0.6872 - accuracy: 0.6665 - val_loss: 0.7599 - val_accuracy: 0.5953\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 6s 52ms/step - loss: 0.5402 - accuracy: 0.7498 - val_loss: 0.5972 - val_accuracy: 0.7085\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 6s 56ms/step - loss: 0.3712 - accuracy: 0.8457 - val_loss: 0.4139 - val_accuracy: 0.8464\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 8s 72ms/step - loss: 0.2697 - accuracy: 0.9066 - val_loss: 0.2769 - val_accuracy: 0.9025\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 6s 54ms/step - loss: 0.2130 - accuracy: 0.9349 - val_loss: 0.2067 - val_accuracy: 0.9428\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.1291 - accuracy: 0.9627 - val_loss: 0.2167 - val_accuracy: 0.9238\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.1153 - accuracy: 0.9705 - val_loss: 0.0995 - val_accuracy: 0.9641\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 7s 63ms/step - loss: 0.1374 - accuracy: 0.9641 - val_loss: 0.0761 - val_accuracy: 0.9697\n",
            "Epoch 12/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.0752 - accuracy: 0.9773 - val_loss: 0.0713 - val_accuracy: 0.9821\n",
            "Epoch 13/25\n",
            "112/112 [==============================] - 5s 49ms/step - loss: 0.0730 - accuracy: 0.9804 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
            "Epoch 14/25\n",
            "112/112 [==============================] - 6s 50ms/step - loss: 0.1193 - accuracy: 0.9806 - val_loss: 0.1580 - val_accuracy: 0.9608\n",
            "Epoch 15/25\n",
            "112/112 [==============================] - 6s 51ms/step - loss: 0.1172 - accuracy: 0.9734 - val_loss: 0.0618 - val_accuracy: 0.9832\n",
            "Epoch 16/25\n",
            "112/112 [==============================] - 5s 49ms/step - loss: 0.0426 - accuracy: 0.9899 - val_loss: 0.0560 - val_accuracy: 0.9865\n",
            "Epoch 17/25\n",
            "112/112 [==============================] - 6s 53ms/step - loss: 0.0263 - accuracy: 0.9944 - val_loss: 0.0073 - val_accuracy: 0.9966\n",
            "Epoch 18/25\n",
            "112/112 [==============================] - 6s 51ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 7.1749e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "112/112 [==============================] - 5s 48ms/step - loss: 0.1152 - accuracy: 0.9921 - val_loss: 0.2201 - val_accuracy: 0.9596\n",
            "Epoch 20/25\n",
            "112/112 [==============================] - 5s 48ms/step - loss: 0.0547 - accuracy: 0.9871 - val_loss: 0.0509 - val_accuracy: 0.9888\n",
            "Epoch 21/25\n",
            "112/112 [==============================] - 5s 48ms/step - loss: 0.4241 - accuracy: 0.9130 - val_loss: 0.2865 - val_accuracy: 0.9439\n",
            "Epoch 22/25\n",
            "112/112 [==============================] - 5s 49ms/step - loss: 0.1056 - accuracy: 0.9753 - val_loss: 0.0428 - val_accuracy: 0.9922\n",
            "Epoch 23/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0110 - val_accuracy: 0.9978\n",
            "Epoch 24/25\n",
            "112/112 [==============================] - 6s 49ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.0080 - val_accuracy: 0.9989\n",
            "Epoch 25/25\n",
            "112/112 [==============================] - 6s 54ms/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.0876 - val_accuracy: 0.9955\n",
            "27/27 [==============================] - 1s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTM6r3PHctwY"
      },
      "outputs": [],
      "source": [
        "# Model 2\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(t, 150,)))\n",
        "model.add(LSTM(400, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(800, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(150, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3,activation='sigmoid'))\n",
        "optimi=keras.optimizers.Adam()\n",
        "\n",
        "# added f1-score here\n",
        "model.compile(optimizer=optimi, loss='sparse_categorical_crossentropy',metrics=['accuracy',get_f1])\n",
        "\n",
        "# fitting model for different epochs\n",
        "# without class weights\n",
        "# history = model.fit(x_train, y_train, epochs=30, validation_split=0.2, verbose=1)\n",
        "\n",
        "# # with class weights\n",
        "model=create_model()\n",
        "history = model.fit(x_train, y_train, epochs=30, validation_split=0.2, verbose=1)\n",
        "test_output = model.predict(x_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbe2pdvQkBhw"
      },
      "outputs": [],
      "source": [
        "# Model 3\n",
        "model3 = Sequential()\n",
        "# model3.add(LSTM(800, activation='relu', return_sequences=True, input_shape=( t,150,)))\n",
        "# model3.add(LSTM(400, activation='relu', return_sequences=True))\n",
        "# model3.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "model3.add(LSTM(200, activation='relu', input_shape=( t,150,)))\n",
        "model3.add(Dense(100, activation='relu'))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "\n",
        "model3.add(Dense(10, activation='sigmoid'))\n",
        "model3.add(Dense(3,activation='sigmoid'))\n",
        "optimi=keras.optimizers.Adam()\n",
        "\n",
        "# added f1-score here\n",
        "model3.compile(optimizer=optimi, loss='sparse_categorical_crossentropy',metrics=['accuracy',get_f1])\n",
        "\n",
        "# fitting model3 for different epochs\n",
        "# history = model3.fit(x_train, y_train, epochs=30, validation_split=0.2, verbose=1)\n",
        "history = model3.fit(x_train, y_train, epochs=20, validation_split=0.2, verbose=1, class_weight=sklearn_weights)\n",
        "test_output3 = model3.predict(x_test, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}